{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk, gensim\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/airline-sentiment.csv',  encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:35</td>\n",
       "      <td>5.703060e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:53</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 10:01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448158</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:05</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448159</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:14</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  681448150    False   finalized                   3      2/25/15 5:24   \n",
       "1  681448153    False   finalized                   3      2/25/15 1:53   \n",
       "2  681448156    False   finalized                   3     2/25/15 10:01   \n",
       "3  681448158    False   finalized                   3      2/25/15 3:05   \n",
       "4  681448159    False   finalized                   3      2/25/15 5:50   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason:confidence         airline airline_sentiment_gold  \\\n",
       "0                        NaN  Virgin America                    NaN   \n",
       "1                     0.0000  Virgin America                    NaN   \n",
       "2                        NaN  Virgin America                    NaN   \n",
       "3                     0.7033  Virgin America                    NaN   \n",
       "4                     1.0000  Virgin America                    NaN   \n",
       "\n",
       "         name negativereason_gold  retweet_count  \\\n",
       "0     cairdin                 NaN              0   \n",
       "1    jnardino                 NaN              0   \n",
       "2  yvonnalynn                 NaN              0   \n",
       "3    jnardino                 NaN              0   \n",
       "4    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "   tweet_created      tweet_id tweet_location               user_timezone  \n",
       "0  2/24/15 11:35  5.703060e+17            NaN  Eastern Time (US & Canada)  \n",
       "1  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "2  2/24/15 11:15  5.703010e+17      Lets Play  Central Time (US & Canada)  \n",
       "3  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "4  2/24/15 11:14  5.703010e+17            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the text to do the following:\n",
    "\n",
    "-Normalize every word to lower case.\n",
    "\n",
    "-Remove punctuation and retain only numbers and alphabets.\n",
    "\n",
    "-Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('[^0-9a-z]+',' ',text)\n",
    "    split = text.split()                                # splits the string by the default delimiter (space) into an array of n length where n is len(string)\n",
    "    stopped = [i for i in split if i not in stop]       # removes stopwords in the split string array\n",
    "    joined=' '.join(stopped)                            # rejoins the array elements into a string\n",
    "    return(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plus added commercials experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>americanair thank got different flight chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>americanair leaving 20 minutes late flight war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>americanair please bring american airlines bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>americanair money change flight answer phones ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>americanair 8 ppl need 2 know many seats next ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                            virginamerica dhepburn said\n",
       "1      virginamerica plus added commercials experienc...\n",
       "2      virginamerica today must mean need take anothe...\n",
       "3      virginamerica really aggressive blast obnoxiou...\n",
       "4                     virginamerica really big bad thing\n",
       "...                                                  ...\n",
       "14635     americanair thank got different flight chicago\n",
       "14636  americanair leaving 20 minutes late flight war...\n",
       "14637  americanair please bring american airlines bla...\n",
       "14638  americanair money change flight answer phones ...\n",
       "14639  americanair 8 ppl need 2 know many seats next ...\n",
       "\n",
       "[14640 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"airline_sentiment\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>virginamerica plus added commercials experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                        virginamerica dhepburn said\n",
       "1          positive  virginamerica plus added commercials experienc...\n",
       "2           neutral  virginamerica today must mean need take anothe...\n",
       "3          negative  virginamerica really aggressive blast obnoxiou...\n",
       "4          negative                 virginamerica really big bad thing"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of words similar to the TFIDF exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist=[]\n",
    "for i in range(len(df)):\n",
    "    wordlist.append(df['text'][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['virginamerica', 'dhepburn', 'said'],\n",
       " ['virginamerica', 'plus', 'added', 'commercials', 'experience', 'tacky'],\n",
       " ['virginamerica', 'today', 'must', 'mean', 'need', 'take', 'another', 'trip'],\n",
       " ['virginamerica',\n",
       "  'really',\n",
       "  'aggressive',\n",
       "  'blast',\n",
       "  'obnoxious',\n",
       "  'entertainment',\n",
       "  'guests',\n",
       "  'faces',\n",
       "  'amp',\n",
       "  'little',\n",
       "  'recourse'],\n",
       " ['virginamerica', 'really', 'big', 'bad', 'thing']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Time\n",
    "\n",
    "Build the Word2Vec model. Define the vector size, context window size to look into, and the minimum count of a word for it to be eligible to have a word vector\n",
    "- size represents the size (dimension) of word vectors.\n",
    "- window represents the context size of words that would be considered.\n",
    "- min_count specifies the minimum frequency based on which a word is considered.\n",
    "- sg represents whether skip-gram used (when sg=1) or CBOW (when sg = 0) used.\n",
    "- alpha is the learning rate (which we'll discuss next week on neural nets proper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Other papers did not report an experiment on embedding dimension size. They are all using an arbitrary dimension on the order of hundreds (100 and 300 are used more frequently). The lack of experiments for embedding size implies that the performance is not very sensitive to this parameter and only the order of magnitude matters, and also other aspects of the model architecture are more important to investigate.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(size=100,window=5,min_count=30, sg=0, alpha = 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14640"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(wordlist)\n",
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['virginamerica', 'said', 'plus', 'experience', 'today', 'must', 'mean', 'need', 'take', 'another', 'trip', 'really', 'amp', 'little', 'big', 'bad', 'thing', 'seriously', 'would', 'pay', '30', 'flight', 'seats', 'flying', 'yes', 'every', 'time', 'fly', 'go', 'away', 'missed', 'without', 'https', 'co', 'well', 'amazing', 'arrived', 'hour', 'early', 'good', 'know', 'second', 'cause', '10', '24', 'lt', '3', 'pretty', 'much', 'better', 'great', 'deal', 'already', '2nd', 'even', '1st', 'yet', 'u', 'travel', 'http', 'thanks', 'sfo', 'schedule', 'still', 'mia', 'first', 'country', 'lax', 'mco', 'heard', 'nothing', 'things', 'virgin', 'flew', 'nyc', 'last', 'week', 'sit', 'seat', 'due', 'two', 'either', 'help', 'awesome', 'bos', 'fll', 'please', 'want', 'may', 'three', 'times', 'available', 'love', 'feel', 'making', 'gt', 'las', 'non', 'stop', 'soon', 'guys', 'friends', 'gave', 'free', 'status', 'weeks', 'called', 'response', 'happened', '2', 'ur', 'food', 'options', 'least', 'say', 'site', 'able', 'anything', 'next', '6', 'hrs', 'fail', 'miss', 'together', 'get', 'cold', 'air', 'ewr', 'middle', 'hi', 'cool', 'birthday', 'add', 'name', 'booking', 'problems', 'hours', 'club', 'online', 'left', 'iad', 'one', 'answering', 'f', 'number', 'return', 'phone', 'call', 'use', 'service', 'option', 'news', 'could', 'start', 'flights', 'end', 'year', 'via', 'nice', 'rt', 'way', 'best', 'ever', 'done', 'airline', 'around', 'book', 'support', 'working', 'beyond', 'hey', 'hard', 'getting', 'account', 'upgrade', 'ticket', 'moved', 'new', 'city', 'leaving', 'dallas', 'feb', 'reason', 'rock', 'wow', 'night', 'think', 'supposed', 'minutes', 'ago', 'website', 'though', 'wish', 'atlanta', 'la', 'lga', 'trying', 'since', 'never', 'thx', 'let', 'us', '4', 'sorry', 'dca', 'tried', 'check', 'someone', 'hold', '40', '50', 'earlier', 'tonight', '11', 'award', 'everything', 'fine', 'lost', 'bag', 'change', 'reservation', 'credit', 'card', 'fee', 'customer', 'team', 'booked', 'baggage', 'needs', 'plane', 'crew', 'airlines', 'like', 'yall', 'sat', 'morning', 'correct', '000', 'different', 'policy', 'media', 'bags', 'going', 'speak', 'human', 'asap', 'thank', 'southwestair', 'jetblue', 'member', 'im', '100', 'delayed', 'late', 'cancelled', 'four', 'business', 'wife', 'bring', 'using', 'share', 'life', 'happens', 'home', 'back', 'yeah', 'points', 'tv', 'disappointed', 'flightled', 'went', 'jfk', 'landed', 'friendly', 'mobile', 'passengers', 'leave', 'told', 'class', 'find', 'anyone', 'direct', 'layover', 'vegas', 'bought', 'people', 'customerservice', 'line', 'hung', 'info', 'scheduled', 'changed', 'weather', 'looks', 'lots', 'come', 'phl', 'horrible', 'flown', 'easy', 'helpful', 'rep', 'front', 'right', 'b', 'c', 'running', 'gate', 'waited', '2015', 'totally', 'problem', 'min', 'delay', 'connecting', 'seems', 'long', 'san', 'provide', '9', 'wait', 'calling', 'completely', 'month', 'customers', 'process', 'link', 'tsa', 'pre', 'terrible', 'hotel', 'assistance', 'yesterday', 'give', 'longer', 'pls', 'always', 'buy', 'frustrated', 'paying', 'extra', 'luggage', 'might', 'world', 'takes', 'flt', 'monday', 'cant', 'staff', 'super', 'paid', 'offer', 'sad', 'question', 'possible', 'giving', 'dc', 'work', 'understand', 'dm', 'answer', 'w', 'kids', '1', 'priority', 'boarding', 'checking', 'tickets', 'happy', 'coming', 'dfw', 'friday', 'error', 'contact', 'minute', 'reschedule', 'fix', 'got', 'checked', 'email', 'tomorrow', 'unacceptable', 'flighted', 'stuck', 'offered', 'look', 'agent', 'airport', 'plans', 'austin', 'route', 'reply', 'waiting', 'checkin', 'desk', 'open', 'luv', 'show', 'united', 'follow', 'many', 'r', 'worse', 'respond', 'money', 'stranded', 'landing', 'southwest', 'days', 'confirmation', 'claim', '8', 'rebook', 'gold', 'lot', 'see', 'worst', 'wrong', 'issue', 'missing', 'lose', 'suck', 'flightlation', 'boston', 'guy', 'high', 'quick', 'apparently', 'sitting', 'sent', 'keep', 'ny', 'pilots', 'job', 'snow', 'area', 'afternoon', 'row', 'mechanical', 'handle', 'twitter', 'charged', 'refund', 'access', 'received', 'broken', 'looking', 'forward', 'rescheduled', 'gonna', 'land', 'cost', '800', 'report', 'attendant', 'something', 'departure', 'fun', 'updates', 'helping', 'passenger', 'destination', 'entire', 'confirmed', 'treat', 'wtf', 'inconvenience', 'full', 'place', 'instead', 'makes', 'cabin', 'pilot', 'tell', 'past', 'husband', 'came', 'despite', 'gives', 'delays', 'says', 'expect', '5', 'safety', 'day', 'wanted', 'newark', 'hope', 'probably', 'board', 'standby', 'helped', 'absolutely', 'ready', 'old', 'less', 'half', 'price', 'round', 'fare', 'made', 'taking', 'care', 'mileage', 'several', 'americanair', 'glad', 'took', 'years', 'try', 'purchase', 'hoping', 'carry', 'empty', 'space', 'spoke', 'loyal', 'family', 'ok', 'currently', 'car', 'sucks', 'cust', 'child', 'chance', 'joke', 'also', 'tix', 'send', 'request', 'ceo', 'planes', 'thought', 'computer', '15', 'cannot', 'guess', 'make', 'address', 'app', 'set', 'system', 'charge', 'tweet', 'houston', 'finally', 'future', 'poor', '1k', 'group', 'room', 'sure', '12', 'shit', 'stay', 'wifi', 'saying', 'point', 'part', 'whole', 'person', 'calls', 'ask', 'flighting', 'luck', 'lol', 'storm', 'complete', 'fees', 'philly', 'months', 'update', 'reps', 'actually', 'word', 'lack', 'ord', 'connections', 'international', 'orlando', 'mins', 'boarded', 'issues', 'oh', 'ridiculous', 'case', 'voucher', 'company', 'maybe', 'pass', 'given', 'miami', 'drive', 'explain', 'talk', 'almost', 'ppl', 'flightr', 'platinum', 'run', 'agents', 'rude', 'overnight', 'hr', 'iah', 'taken', 'used', 'details', 'charlotte', 'form', 'ground', 'else', 'appreciate', 'tarmac', 'enough', 'denver', 'put', 'found', 'supervisor', 'thru', 'connection', 'upset', 'services', 'employees', 'mom', '7', 'miles', 'american', 'rather', 'telling', 'delta', 'attendants', 'seem', 'believe', 'bc', 'record', 'asking', 'read', 'everyone', 'ua', 'aircraft', 'knew', 'winter', 'reach', 'hear', 'mine', 'apology', 'goes', 'zero', 'date', 'members', 'weekend', 'asked', 'held', '25', 'message', 'complaint', 'awful', 'jet', 'atl', 'traveling', 'works', 'communication', 'far', 'top', 'unitedairlines', 'kudos', 'extremely', 'real', 'clothes', 'leg', 'chicago', 'lounge', 'okay', 'load', 'terminal', 'arrival', '20', 'information', 'confirm', 'vacation', 'nope', 'sleep', 'compensation', 'original', 'happen', 'delivered', 'arrive', 'employee', 'answers', 'clt', 'idea', 'responding', 'frustrating', 'figure', 'counter', 'unfortunately', 'fact', 'needed', 'means', 'bwi', 'pm', 'fixed', 'unable', 'ice', 'phones', 'den', 'fleet', 'spent', 'situation', 'list', 'changes', '200', 'control', 'aa', 'reservations', 'reflight', '45', 'seen', 'tuesday', 'id', 'multiple', 'maintenance', 'friend', 'twice', 'allowed', 'counting', 'rebooked', 'sunday', 'sense', 'hate', 'huge', 'hopefully', 'rdu', 'usairways', 'pick', 'crazy', 'airways', 'gets', 'treated', 'fault', 'sending', 'losing', 'nashville', 'changing', 'switch', 'flightlations', 'dont', 'appreciated', 'hang', 'plan', 'following', 'runway', 'true', 'live', 'busy', 'allow', 'hello', 'relations', 'disconnected', 'water', 'bna', 'kind', 'phx', 'automated', 'companion', 'haha', 'sw', 'holding', 'swa', 'destinationdragons', 'imaginedragons', 'usair', 'blue', 'fleek', 'wall'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8553951, 15367300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(wordlist, total_examples=model.corpus_count, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.48231843,  1.1854167 ,  1.3057796 ,  2.704182  ,  0.37052798,\n",
       "        2.0038793 ,  0.9172721 ,  0.6268933 ,  0.84013146,  0.74631107,\n",
       "        1.8647486 , -2.1524239 ,  2.1252522 , -1.7364016 ,  3.2661128 ,\n",
       "       -0.24306428,  0.885861  , -0.02458498, -0.01559705,  1.1451176 ,\n",
       "       -2.7282014 ,  2.8703492 , -0.02892786,  1.9754671 , -1.2780055 ,\n",
       "       -1.8831369 ,  0.34850353, -0.10792898,  1.4820467 , -1.0494508 ,\n",
       "        1.0482062 , -0.69732994, -1.3389028 ,  1.0235748 ,  0.63351935,\n",
       "       -1.0640191 , -1.2512885 ,  0.43683174, -1.0858021 ,  0.90441006,\n",
       "       -0.5989638 , -2.4551308 , -1.4814669 , -1.1503303 , -0.83055186,\n",
       "        2.402597  , -0.7774185 ,  1.0959852 ,  0.2802829 ,  1.377494  ,\n",
       "        0.61431944,  0.29719478, -0.45385975, -0.37440434, -1.2918323 ,\n",
       "       -3.6284623 ,  3.436852  ,  0.5862328 ,  0.06993027,  1.768561  ,\n",
       "       -1.1991277 ,  0.97763187, -0.8115031 ,  0.81149924,  2.271642  ,\n",
       "        0.16454464,  0.20165619,  1.1812941 ,  1.6315712 ,  1.6692148 ,\n",
       "        0.78900707,  1.9511864 , -0.26805633, -0.3449418 , -0.46269643,\n",
       "        0.386227  , -1.0043142 , -0.10097487, -0.47411618, -1.3319085 ,\n",
       "        3.8482018 , -3.0502675 , -1.6707687 ,  1.3808879 ,  1.8052063 ,\n",
       "        1.1802663 , -0.5098927 ,  1.4635154 ,  1.0050231 , -0.76362914,\n",
       "        0.47945035,  0.26248148,  0.11026824,  2.3135254 ,  1.443164  ,\n",
       "        0.739548  ,  0.890423  ,  1.0228562 , -2.9993527 , -0.9729914 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.7351747 ,  1.1413084 ,  0.5122892 , -0.99221253, -1.931554  ,\n",
       "        3.7524939 ,  0.7697424 , -0.53768146,  0.5430797 ,  0.7762832 ,\n",
       "        4.0712166 , -0.20129006,  2.2683547 , -1.0918876 ,  1.3096377 ,\n",
       "       -0.10507166,  1.6186359 ,  0.8245387 ,  0.85729265, -1.2718667 ,\n",
       "        1.0588065 ,  2.926049  , -2.3719544 ,  0.3972117 , -0.26262942,\n",
       "       -0.54822576,  1.3490062 , -0.8417923 ,  0.27009058, -0.80906385,\n",
       "        1.2567332 , -1.0184585 ,  0.31484777,  1.260187  , -1.7579784 ,\n",
       "       -2.6931052 ,  1.2413775 , -1.5042392 , -1.7027707 ,  2.6120007 ,\n",
       "       -0.95892274, -1.7700498 , -3.2436838 , -1.3693079 , -2.450128  ,\n",
       "        3.741627  , -0.3456695 , -0.4773855 ,  0.07111122, -0.06782713,\n",
       "        1.281503  ,  2.1346712 , -1.1422708 , -1.7912444 , -1.1381606 ,\n",
       "       -2.446876  ,  0.74280083,  0.25676063,  0.54744977, -1.7652304 ,\n",
       "       -3.750914  ,  1.7294987 , -0.27741864,  0.19899717,  4.037618  ,\n",
       "        1.4246479 ,  0.58231133,  1.869954  ,  1.0336992 ,  0.3305884 ,\n",
       "        0.8726357 ,  3.466552  ,  0.28285134, -1.0857341 , -1.3967359 ,\n",
       "        0.6546086 , -0.42472646,  1.7785326 , -2.08521   , -1.6112546 ,\n",
       "       -1.4473523 , -2.274407  , -1.5068417 ,  0.27944434,  0.5563313 ,\n",
       "        1.0130583 , -3.0698173 ,  0.5734534 , -1.0428121 , -0.82317644,\n",
       "        2.1353426 , -1.4507384 , -2.5728061 , -1.5457264 , -0.91222477,\n",
       "        1.2067705 ,  1.9783709 ,  1.3549783 , -2.2556064 , -2.030808  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.51448256"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('month','year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('year', 0.5144824981689453),\n",
       " ('week', 0.4374368190765381),\n",
       " ('months', 0.3897380828857422),\n",
       " ('weeks', 0.3710346221923828),\n",
       " ('trip', 0.3644384443759918),\n",
       " ('leg', 0.34222888946533203),\n",
       " ('night', 0.29254746437072754),\n",
       " ('child', 0.27689963579177856),\n",
       " ('years', 0.2697194218635559),\n",
       " ('days', 0.2673693895339966),\n",
       " ('awful', 0.257131963968277),\n",
       " ('bought', 0.25409895181655884),\n",
       " ('11', 0.2468951940536499),\n",
       " ('day', 0.24680420756340027),\n",
       " ('000', 0.2437877207994461),\n",
       " ('virgin', 0.24148401618003845),\n",
       " ('points', 0.24074023962020874),\n",
       " ('miles', 0.24056807160377502),\n",
       " ('minute', 0.23998117446899414),\n",
       " ('fun', 0.23998035490512848)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('month', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/.pyenv/versions/3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('year', 0.48174652457237244),\n",
       " ('week', 0.3972211480140686),\n",
       " ('months', 0.3078358769416809),\n",
       " ('leg', 0.2995736598968506),\n",
       " ('weeks', 0.29844123125076294),\n",
       " ('awful', 0.29741552472114563),\n",
       " ('night', 0.2811007499694824),\n",
       " ('trip', 0.28102344274520874),\n",
       " ('running', 0.2368464469909668),\n",
       " ('whole', 0.233427032828331)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_uf = Word2Vec(size=100,window=5,min_count=30, sg=0)\n",
    "model_uf.build_vocab(wordlist)\n",
    "model_uf.train(wordlist, total_examples=model.corpus_count, epochs=200)\n",
    "model_uf.most_similar('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
